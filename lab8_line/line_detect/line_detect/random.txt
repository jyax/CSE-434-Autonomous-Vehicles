LAB 5 FILES
add_data_channels.py

''' add_data_channels.py

    Add extra channels to data with the goal of improving a linear classifier

'''

from labeled_data import LabeledData

def add_rotated_vectors(measurements: LabeledData):
    ''' Adds 2 extra channels to measurements.data
        Assumes measurements has already been initialized with data having at least 2 dimensions

        It is not permitted to add new information, only to rearrange the data already in measurements
        Hence, the channels must be functions of x and y (the first two channels of data)
        This example adds a rotated and scaled versions of x and y
        Since this is just a linear transformation of the data, it will not actually help the classifier.

        Your task is to create a similar function, but to add two non-linear operations on x and y so that the
        classifier can better separate the targets from clutter

        Example usage:
          train = LabeledData( <path_to_data> )
          train_plus = add_rotated_vectors(train)

          test = LabeledData( <path_to_data> )
          test_plus = add_rotated_vectors(test)
    '''
    x = measurements.get_x()
    y = measurements.get_y()
    measurements.add_data_channels( x + y )
    measurements.add_data_channels( -x + y )

    return measurements

def add_rvec(measurements: LabeledData):
    ''' Adds 2 extra channels to measurements.data
        Assumes measurements has already been initialized with data having at least 2 dimensions
    '''
    x = measurements.get_x()
    y = measurements.get_y()
    measurements.add_data_channels( (x+y-7.5)**2 )
    measurements.add_data_channels( (-x+y)**2 )

    return measurements
======================================================
classifier.py
''' classifier.py

    Point classification using logistic regression

    Daniel Morris, Nov 2022

    python -m pip install -U scikit-learn
'''

import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import average_precision_score
import matplotlib.pyplot as plt
from labeled_data import LabeledData

class Classifier:

    def __init__(self) -> None:
        self.cvec = np.array([])
        self.intercept = np.array([])
        self.logr = LogisticRegression(class_weight='balanced',solver='lbfgs')

    def fit(self, mydata ):
        self.logr.fit(mydata.data,mydata.labels)
        self.cvec = self.logr.coef_.ravel()
        self.intercept = np.array( self.logr.intercept_)

    def classify(self, mydata):
        ''' Returns scores '''
        if self.cvec.size==0:
            print('Must fit model before classifying data')
            raise Exception
        return (mydata.data * self.cvec[None,:]).sum(axis=1) + self.intercept[0]

    def plot_line_on_axes(self, xchan=0, ychan=1, label='Line', color=[0,0,0], linestyle='-', block=True):
        ''' Plots 2D line on current axes corresponding to:
            self.cvec[xchan]*x + self.cvec[ychan]*y + self.intercept = 0
        '''
        xminmax = np.array(plt.gca().get_xlim())
        yminmax = np.array(plt.gca().get_ylim())

        yvals = (-self.cvec[xchan]*xminmax - self.intercept[0]) / self.cvec[ychan]
        xvals = (-self.cvec[ychan]*yminmax - self.intercept[0]) / self.cvec[xchan]

        # find pair of locations that line intersects the axes:
        intersect = []
        if yvals[0]>=yminmax[0] and yvals[0]<=yminmax[1]:
            intersect.append( [xminmax[0],yvals[0]] )
        if yvals[1]>=yminmax[0] and yvals[1]<=yminmax[1]:
            intersect.append( [xminmax[1],yvals[1]] )
        if xvals[0]>=xminmax[0] and xvals[0]<=xminmax[1]:
            intersect.append( [xvals[0],yminmax[0]] )
        if xvals[1]>=xminmax[0] and xvals[1]<=xminmax[1]:
            intersect.append( [xvals[1],yminmax[1]] )

        if len(intersect):
            line = np.array(intersect)
            plt.plot( line[:,0], line[:,1], color=color, linestyle=linestyle, label=label )
        else:
            print('Line does not intersect axes')

        if block:
            plt.legend()
        plt.show(block=block)

    def plot_all_points(self, points, fignum='Points', title=None, block=True, filesave=None):

        target = points.get_subset(points.labels==1)
        clutter = points.get_subset(points.labels==0)
        Nplots = points.data.shape[1] // 2
        fig = plt.figure(fignum,figsize=(5*Nplots,4))
        for p in range(Nplots):
            plt.subplot(1,Nplots,p+1)
            xchan, ychan = 2*p, 2*p+1
            target.plot_points(xchan=xchan, ychan=ychan, c=[[.1,.8,.1]], label='Target', block=False)
            clutter.plot_points(xchan=xchan, ychan=ychan, c=[[.1,.1,.8]], label='Clutter', block=False)
            plt.legend(fontsize='small')
        plt.suptitle(title)
        if filesave:
            plt.savefig(filesave)
        plt.show(block=block)


    def plot_results(self, points, scores, fignum='Result', block=True, filesave=None):
        '''
            points: data points
            scores: output of model.classify(points)
        '''
        t_correct = points.get_subset( np.logical_and(points.labels, scores>0) )
        c_correct = points.get_subset( np.logical_and(points.labels==0, scores<=0) )
        all_wrong = LabeledData()
        all_wrong.append( points.get_subset( np.logical_and(points.labels, scores<=0) ) )
        all_wrong.append( points.get_subset( np.logical_and(points.labels==0, scores>0) ) )

        n_true_positives = np.logical_and(points.labels, scores>0).sum()
        n_false_positives = np.logical_and(points.labels==0, scores>0).sum()
        n_false_negatives = np.logical_and(points.labels, scores<=0).sum()

        precision = n_true_positives / (n_true_positives + n_false_positives)
        recall = n_true_positives / (n_true_positives + n_false_negatives)

        average_precision = average_precision_score(points.labels.astype(bool), scores)

        Nplots = points.data.shape[1] // 2
        # Plot channels pairwise:
        fig = plt.figure(fignum,figsize=(5*Nplots,4))
        for p in range(Nplots):
            plt.subplot(1,Nplots,p+1)
            xchan, ychan = 2*p, 2*p+1
            t_correct.plot_points(xchan=xchan, ychan=ychan, c=[[.1,.8,.1]], label='TP', block=False)
            c_correct.plot_points(xchan=xchan, ychan=ychan, c=[[.1,.1,.8]],  label='TN', block=False)
            all_wrong.plot_points(xchan=xchan, ychan=ychan, c='r',  label='FP+FN', block=False)
            self.plot_line_on_axes(xchan=xchan, ychan=ychan, label='T=0', block=False)
            plt.legend(fontsize="small")

        plt.suptitle(f'Av Precision: {average_precision:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, Nchan: {points.data.shape[1]}')

        if filesave:
            plt.savefig(filesave)
        plt.show(block=block)

=======================================
labeled_data.py
''' labeled_data.py

    Data Point class used for testing Logistic Regression

    Daniel Morris, Nov 2022

'''
from re import L
import numpy as np
import csv
import matplotlib.pyplot as plt

class LabeledData:

    def __init__(self, other=None) -> None:
        '''
            other: Can initialize with another LabeledData (and makes a copy) or with a csv filename and reads it.
            self.data: [N x M] for N points each with M channels
            self.labels: length N vector with 1 for target and 0 for clutter
        '''
        if isinstance(other,LabeledData):
            self.data = other.data.copy()
            self.labels = other.labels.copy()
        elif isinstance(other,str):
            self.read(other)
        else:
            self.data  = np.array([])
            self.labels = np.array([])

    def get_x(self):
        ''' Returns x channel '''
        return self.data[:,0]

    def get_y(self):
        ''' Returns y channel'''
        return self.data[:,1]


    def append( self, other):
        if self.data.size==0:
            self.data = other.data.copy()
            self.labels = other.labels.copy()
        else:
            self.data = np.concatenate( (self.data, other.data))
            self.labels = np.concatenate( (self.labels, other.labels))

    def get_subset(self, selected):
        subset = LabeledData()
        subset.data = self.data[selected,...]
        subset.labels = self.labels[selected]
        return subset

    def add_data_channels(self, data_channels):
        ''' Adds one or more channels to data
            data_channel: NxM where N is number of points and M is number of channels
                          N must be the same as self.data
        '''
        if self.data.shape[0] != data_channels.shape[0]:   # Check that there are N points
            print(f'data_channels must be defined for N={self.data.shape[0]} samples')
            raise ValueError
        if len(data_channels.shape)==1:   # If a vector, then reshape to be Nx1
            data_channels = data_channels[:,None]
        self.data = np.concatenate( (self.data, data_channels), axis=1 )


    def write(self, name):
        with open(name, 'w', newline='') as csvfile:
            ptwriter = csv.writer(csvfile, delimiter=',')
            for label, pt in zip(self.labels,self.data):
                ptwriter.writerow((label,*pt))

    def read(self, name):
        with open(name, newline='') as f:
            ptreader = csv.reader(f, delimiter=',')
            vals = np.array(list(ptreader))
        self.labels = vals[:,0].astype(int)
        self.data = vals[:,1:].astype(float)

    def plot_points(self, xchan=0, ychan=1, label=None, c=None, block=True):
        ''' Plots 2 channels of points
            xchan: which channel to be on x axis
            ychan: which channel to be on y axis
        '''
        plt.grid(True, linestyle='--')
        plt.gca().set_aspect('equal')

        plt.scatter(self.data[:,xchan], self.data[:,ychan], c=c, label=label)

        plt.xlabel(f'chan: {xchan}')
        plt.ylabel(f'chan: {ychan}')

        if block:
            plt.legend()
        plt.show(block=block)
=======================================
logist_reg.py
#!/usr/bin/env python
'''
    Logistic Regression
    To solve for a pixel-wise logistic regression model, do:

    python logist_reg.py trainimname trainmaskname testimname --testmask testmaskname

    Once you have solved for these parameters, you can apply them to an image with
    the apply() function.  This outputs a probability image for pixels in the image.

    Daniel Morris, April 2020
    Copyright 2020
'''
import os
import numpy as np
import argparse
import cv2 as cv
from scipy.special import expit  # Sigmoid function
from sklearn.metrics import average_precision_score

def plotClassifcation( img, mask, pixProbs, threshold=0.5, savename='', outfolder='.'):
    ''' Plot Classification Image Results, and output to files '''
    cv.imshow("Image", img)
    cv.imshow("Raw Output", pixProbs )
    if mask.any():
        cv.imshow("Ground Truth Mask", mask)

        #Create colored scoring image:
        TP = np.logical_and( mask > 0, pixProbs > threshold )   # green
        FP = np.logical_and( mask == 0, pixProbs > threshold )  # red
        FN = np.logical_and( mask > 0, pixProbs <= threshold )  # blue
        #add gray color if any of the above labels to reduce contrast slightly
        alabel = TP + FP + FN
        # R,G,B classification for FP, TP, FN:
        eimg = np.stack( (FN, TP, FP), axis=2 ).astype(np.uint8) * 180 + 75 * alabel[:,:,None].astype(np.uint8)
        # Superimpose this on grayscale image:
        gimg = img.mean(axis=2).astype(np.uint8)
        combimg = (eimg * 3.0/5.0 + gimg[:,:,None] * 2.0/5.0).astype(np.uint8)
        cv.imshow("Scoring Using Mask", combimg)
    if outfolder:
        os.makedirs(outfolder,exist_ok=True)
        cv.imwrite(os.path.join(outfolder,'prob_'+savename), np.uint8(pixProbs*255) )
        if mask.any():
            cv.imwrite(os.path.join(outfolder,'scoring_'+savename), combimg )

def plotTargets(img, target_mask, centroids, savename='', outfolder=''):
    ''' Plot detected target_mask and output to file
        img: image (NxMx3) numpy array
        target_mask: (NxM) numpy array, or else empty list
        centroids: list of [x,y] centroids
    '''
    if isinstance(target_mask,list):
        target_mask = np.array(target_mask)  # Needs to be a numpy array
    if target_mask.size:  # Check if not empty numpy array:
        # Then highlight the detected pixels in the original image
        green = np.zeros_like(img)
        green[:,:,1] = 128
        mask = target_mask[:,:,None].repeat(3,axis=2)
        outim = img.copy() * (1-mask) + (img.copy()//2 + green) * mask
    else:
        outim = img.copy()
    for centroid in centroids:
        loc = tuple( np.array(centroid).astype(int) )  # location needs to be int tuple
        cv.circle(outim, loc, 5, (0,0,255), -1 )
    cv.imshow("Target", outim)
    if outfolder:
        os.makedirs(outfolder,exist_ok=True)
        cv.imwrite(os.path.join(outfolder,'target_'+savename), outim )

def imread_channel( filename ):
    ''' Read in image and return first channel '''
    img0 = cv.imread( filename )
    if img0 is None:
        print('Warning, unable to read:', filename)
    if len(img0.shape)==3:
        img0 = img0[:,:,0]
    return img0

class LogisticReg:
    def __init__(self ):
        ''' Initialize class with zero values '''
        self.cvec = np.zeros( (1,3) )
        self.intercept = np.zeros( (1,) )

    def set_model(self, cvec, intercept):
        ''' Set model parameters manually
            cvec:      np.array([[p1,p2,p3]])
            intercept: np.array([p4])
        '''
        self.cvec = cvec
        self.intercept = intercept

    def fit_model_to_files(self, img_name, mask_name, exmask_name='', mod_channels=False):
        ''' Load images from files and fit model parameters '''
        img = cv.imread( img_name )
        mask = imread_channel( mask_name )
        if img is None or mask is None:
            print('Error loading image and mask')
            print('image:', img_name)
            print('mask:', mask_name)
        if exmask_name:
            exmask = imread_channel(exmask_name)
        else:
            exmask = np.array([])
        if mod_channels:
            img = self.modify_img_channels(img)
        self.fit_model( img, mask, exmask )

    def modify_img_channels(self, img):
        hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)
        return np.concatenate( (img,hsv[:,:,:]), axis=2 )

    def fit_model(self, img, mask, exmask=np.array([]) ):
        ''' Do logistic regression to discriminate points in non-zero region of
            mask from other points in mask and save estimated logistic regression parameters
            exmask: optionally exclude some pixels from image '''
        # Only need sklearn when we fit model parameters -- Do not require this for inference, see apply()
        from sklearn.linear_model import LogisticRegression
        data = img.reshape((-1,img.shape[2])).astype(float)   # Reshape to N x 3
        label = (mask.ravel()>0).astype(int)       # Reshape to length N
        if exmask.any():                    # Optionally exclude pixels
            keep = exmask.ravel()==0
            data = data[keep,:]
            label = label[keep]
        sk_logr = LogisticRegression(class_weight='balanced',solver='lbfgs')
        sk_logr.fit( data, label)
        self.cvec      = sk_logr.coef_                # Extract coefficients
        self.intercept = np.array(sk_logr.intercept_) # Extract intercept

    def print_params(self):
        print('Logist Regression params, cvec:',self.cvec,'intercept:',self.intercept)

    def apply(self, img, mod_channels=False):
        ''' Application of trained logisitic regression to an image
            img:         [MxNx3] input 3-channel color image
            score:       [MxN] logistic regression score for each pixel (between -inf and inf)
        '''
        if mod_channels:
            img = self.modify_img_channels(img)
        # Here is a solution using broadcasting:
        score = (img.astype(float) * self.cvec).sum(axis=2) + self.intercept
        # An alternate solution: reshaping the image and using inner products followed by broadcasting is:
        # data = img.reshape((-1,3)).astype(float)
        # score = (np.inner(data,self.cvec) + self.intercept).reshape( img.shape[0:2] )
        return score

    def prob_target(self, score):
        ''' Transforms score to probability of target using sigmoid '''
        return expit( score )

    def find_largest_target(self, prob_target, threshold=0.5, minpix=20):
        ''' Finds largest contiguous target region
            This takes the output of logistic regression, thresholds it
            and finds the largest contiguous region and returns its centroid
            Useful for simple cases where you are sure that the target is the
            largest object in the image of its color.
            prob_target: [MxN] input probability of target
            centroid:    [x,y] coordinates of the largest centroid
            area:        number of pixels in target
            target_mask: [MxN] binary mask with 1's at target
        '''
        binary_target = (prob_target>threshold).astype(np.uint8)
        cc = cv.connectedComponentsWithStats(binary_target)
        inds = np.argsort( cc[2][:,4] )  # Sort on number of pixels in each continguous region
        target_mask = np.zeros_like(binary_target)
        centroid = []
        area = []
        for i in inds[::-1]:
            # If the average probability of target in region > 0.99 and has >= minpix
            if binary_target[cc[1]==i].astype(float).mean() > 0.99 and cc[2][i,4] >= minpix:
                # Then keep this region
                target_mask += (cc[1]==i).astype(np.uint8)  # add these pixels to output
                centroid = cc[3][i,:]
                area = cc[2][i,4]
                break
        return centroid, area, target_mask

    def find_all_targets(self, prob_target, threshold=0.5, minpix=20):
        ''' Finds contiguous target regions
            This takes the output of logistic regression, thresholds it
            and finds contiguous regions in the image of target pixels.
            prob_target: [MxN] input probability of target
            centroids:   list of [x,y] coordinates of target centroids
            areas:       list of number of pixels in each target
            target_mask: [MxN] binary mask with 1's at each target pixel
        '''
        binary_target = (prob_target>threshold).astype(np.uint8)
        cc = cv.connectedComponentsWithStats(binary_target)
        inds = np.argsort( cc[2][:,4] )  # Sort on number of pixels in each continguous region
        target_mask = np.zeros_like(binary_target)
        centroids = []
        areas = []
        for i in inds[::-1]:
            # If the average probability of target in region > 0.99 and has >= minpix
            if binary_target[cc[1]==i].astype(float).mean() > 0.99 and cc[2][i,4] >= minpix:
                # Then keep this region
                target_mask += (cc[1]==i).astype(np.uint8)  # add these pixels to output
                centroids.append( cc[3][i,:] )
                areas.append( cc[2][i,4] )
        return centroids, areas, target_mask



if __name__ == '__main__':
    # This is a demonstration of how LogisticReg can be used
    parser = argparse.ArgumentParser(description='Logistic Regression')
    parser.add_argument('trainimg',      type=str,              help='Train image')
    parser.add_argument('trainmask',     type=str,              help='Train mask')
    parser.add_argument('testimg',       type=str,              help='Test image')
    parser.add_argument('--testmask',    type=str, default='',  help='Test mask')
    parser.add_argument('--trainexmask', type=str, default='',  help='Train pixels to exclude')
    parser.add_argument('--threshold', type=float, default=0.5, help='Target pixel threshold')
    parser.add_argument('--outfolder',   type=str, default='',  help='Folder to save images, if empty do not save')
    parser.add_argument('--mod-channels', dest='mod_channels', action='store_true', help='Modify image channels')
    parser.add_argument('--find-target', dest='find_target', action='store_true', help='Find largest target')
    args = parser.parse_args()

    # Build color model with Logistic Regression
    logr = LogisticReg( )
    logr.fit_model_to_files( args.trainimg, args.trainmask, args.trainexmask, mod_channels=args.mod_channels )

    # Load test data:
    testimg = cv.imread(args.testimg)
    if args.testmask:
        testmask = imread_channel(args.testmask)
    else:
        testmask = np.array([])

    # Apply model to test data:
    score = logr.apply( testimg, mod_channels=args.mod_channels )
    probt = logr.prob_target( score )
    logr.print_params()
    if testmask.size:
        # If we provide ground truth on test data, we can calculate the average precision:
        average_precision = average_precision_score(testmask.ravel()*255, score.ravel() )
        print(f'Average precision: {average_precision:.3f}')

    if args.outfolder:
        print('Saving output images to:',args.outfolder)
    # Plot classification results:
    plotClassifcation(testimg, testmask, probt, args.threshold, os.path.basename(args.testimg), args.outfolder )

    if args.find_target:
        # Find largest regions as targets
        centroid, area, target = logr.find_largest_target(probt, args.threshold)
        # Plot detected region and centroid:
        plotTargets(testimg, target, [centroid], os.path.basename(args.testimg), args.outfolder )
    cv.waitKey()
    cv.destroyAllWindows()
=======================================
test_set_1.py
''' test_set_1.py

    Demo script to train and test a point-based classifier for dataset 1

    Folders should be organized:
    src / test_set_1.py  (+ other python files)
    data / set_1_train.csv (+ other data files)

'''
from pathlib import Path
from labeled_data import LabeledData
from classifier import Classifier

path = Path(__file__).parents[1] / 'data'  # Get path to data folder

train = LabeledData( str( path / 'set_1_train.csv' ) )  # Load train data
test = LabeledData( str( path / 'set_1_test.csv' ) )    # Load test data

model = Classifier()

# Fit classifier parameters to training data:
model.fit(train)

# Plot target and clutter points from test set:
model.plot_all_points(test, fignum='Input_1', title='Test Data 1', block=False)

# Classify test points:
scores = model.classify(test)

# Plot classification results:
model.plot_results(test, scores, fignum='Result_1', block=True)
===================================
test_set_2.py

''' test_set_2.py

    Demo script to train and test a point-based classifier for dataset 2

'''

import os
from labeled_data import LabeledData
from classifier import Classifier
from add_data_channels import add_rotated_vectors

train = LabeledData( '../data/set_2_train.csv')
test = LabeledData( '../data/set_2_test.csv')

model = Classifier()

# Fit classifier parameters to training data:
model.fit(train)

# Plot target and clutter points from test set:
model.plot_all_points(test, fignum='Input_2',
                      title='Test Data 2', block=False, filesave='../images/set_2.png')

# Classify test points:
scores = model.classify(test)

# Plot classification results:
model.plot_results(test, scores, fignum='Result_2', block=True, filesave='../images/set_2_classify.png')

========================================
test_set_2_plus.py
''' test_set_2_plus.py

    Demo script to train and test a point-based classifier for dataset 2

'''

import os
from labeled_data import LabeledData
from classifier import Classifier
from add_data_channels import add_rotated_vectors, add_rvec

path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data')

train = LabeledData( '../data/set_2_train.csv')
test = LabeledData( '../data/set_2_test.csv')


# ---------------------------------------------------
# Create your own function in add_data_channels.py that adds extra channels and
# use that instead of add_rotated_vectors()

train_plus = add_rvec(train)
test_plus = add_rvec(test)

# ---------------------------------------------------

# Now train with 4 channels:
model_plus = Classifier()

model_plus.fit(train_plus)

nchannels = train_plus.data.shape[1]
model_plus.plot_all_points(test_plus, fignum='Input_3',
                           title=f'Augmented Test Data 2, Nchannels: {nchannels}', block=False)

scores = model_plus.classify(test_plus)

model_plus.plot_results(test_plus, scores, fignum='Result_3', block=True)
